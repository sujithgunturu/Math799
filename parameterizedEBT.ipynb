{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "parameterizedEBT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OlZvFIcSkCu",
        "colab_type": "text"
      },
      "source": [
        "# EBT Cohort Simulation for the Simple Wheat Model\n",
        "<div style=\"margin-top: 20px; margin-left: 20px; font-size: 90%; color: #888888\">\n",
        "by Adriana M. Ortiz Aquino, Elizabeth J. Hale, Lauren M. White, Md. Atiqul Islam, Saikat Kuili  \n",
        "    \n",
        "Based on EBT Model by Nathan Albin &lt;albin@ksu.edu&gt;<br>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hh-srqmSkCw",
        "colab_type": "text"
      },
      "source": [
        "In homework 5 we created a model class and then another subclass for the simple wheat model using the equations \n",
        "$$\n",
        "\\begin{align}\n",
        "\\frac{d}{dt} TT &= \\max (T_{avg}-T_{base},0) \\\\\n",
        "\\frac{d}{dt} LAI &= \\begin{cases} &\\alpha \\max (T_{avg}-T_{base},0) LAI\\cdot \\max(LAI_{max}-LAI,0) \\quad \\text{ if } TT\\leq TTL \\\\\n",
        "&0 \\quad \\text{otherwise}\n",
        "\\end{cases} \\\\\n",
        "\\frac{d}{dt} B &= \\begin{cases}  &RUE[1-e^{-K\\cdot LAI}]I \\quad \\text{ if } TT\\leq TTM \\\\\n",
        "&0 \\quad \\text{otherwise}\n",
        "\\end{cases}\n",
        "\\end{align}.\n",
        "$$\n",
        "\n",
        "We desire to run simulations using these models for a variety of initial conditions.  However, this will eventually be computationally intensive as our models account for more factors and become more complex, so we have this second class, EBT, designed to mitigate this issue.\n",
        "\n",
        "For EBT, we generate a population mean and a population covariance for the initial values for thermal temperature, leaf area index, and biomass, which EBT then uses to solve the differential equations to model the plant growth.  The process of selecting the population information, adapting the model class to fit with the EBT class, and running the class are discussed throughout.\n",
        "\n",
        "Overall, second-order EBT does quite well, matching very closely with simulation using several different samples of initial value times.  This process made apparent a few changes we felt would be wise to keep in mind as we continue to modify our model of the wheat plant, especially related to growth rate of leaf area index and biomass.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STC98q8pSkCy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72e14f83-4a90-4088-f001-e180ce129580"
      },
      "source": [
        "%matplotlib inline\n",
        "import pandas as pd                    # Import panda for reading env data\n",
        "import numpy as np                     # Import array funtions\n",
        "import math                            # Import all math functions\n",
        "import matplotlib.pyplot as plt        # Import plotting functions\n",
        "import ephem as em                     # Import pyephem to get daylight data\n",
        "from datetime import *   \n",
        "import autograd.numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import pchip\n",
        "from scipy.integrate import odeint, RK45,ode\n",
        "import scipy.linalg as sla\n",
        "from autograd import grad, jacobian\n",
        "from scipy.cluster.vq import kmeans2\n",
        "!pip install sobol-seq\n",
        "import sobol_seq"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sobol-seq\n",
            "  Downloading https://files.pythonhosted.org/packages/e4/df/6c4ad25c0b48545a537b631030f7de7e4abb939e6d2964ac2169d4379c85/sobol_seq-0.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sobol-seq) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sobol-seq) (1.18.5)\n",
            "Installing collected packages: sobol-seq\n",
            "Successfully installed sobol-seq-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMsBuAkTSkC8",
        "colab_type": "text"
      },
      "source": [
        "## Set up Model Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbvkwaJzSkC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Model Class Definition\"\"\"\n",
        "\n",
        "class Model(object):\n",
        "    \n",
        "    #Attributes we want each instance of model to have\n",
        "    def __init__(self,Eqns):\n",
        "        self.Eqns = Eqns  #\n",
        "        self.n_var = len(Eqns)\n",
        "        self.solution=[]  # creates a new empty list for each model\n",
        "        self.params=None   # Initialize parameter values\n",
        "        \n",
        "        self.y0=None      # Initialze initial state variables\n",
        "        \n",
        "        self.t=None       # Initialie array of times at which solutions are sought\n",
        "        \n",
        "        self.Env=None     # Set flag that the simulation environment is not yet defined\n",
        "                          #    When it is, it will most likely be an array with one\n",
        "                          #    row per measurement time and one column per environmental\n",
        "                          #    variable.\n",
        "        self.day_length=None\n",
        "        \n",
        "                    \n",
        "    # Store a vector of desired solution times\n",
        "    def new_soltimes(self,t):\n",
        "        self.t=np.array(t)\n",
        "    \n",
        "    # Store a vector of desired state variable initial conditions\n",
        "    def new_ICs(self,y0):\n",
        "        self.y0=np.array(y0)\n",
        "    \n",
        "    # Store a vector of model parameters - this is used during parameter estimation\n",
        "    def new_params(self,params):\n",
        "        self.params=np.array(params)\n",
        "        \n",
        "    \n",
        "    \"\"\" The following two methods are overloaded in the users class definition \"\"\"\n",
        "    \n",
        "    # Fetch the environmental information from a file.  \"Environ\" is \n",
        "    # whatever information is needed to do this.\n",
        "    def FetchEnviron(self,Environ):\n",
        "        pass\n",
        "    \n",
        "    # Get the specific environment data for time t.  Depending on the time step\n",
        "    # this might entail interpolation between observation times  The actual vector \n",
        "    # size will depend on model specifics.\n",
        "    def GetEnvData(self,t):\n",
        "        self.Edat=np.zeros(3)\n",
        "        \n",
        "        \n",
        "    # Run the model\n",
        "    def Run(self,ICs=None,params=None,t=None,Environ=None):\n",
        "        \n",
        "        # Perform any needed initializations\n",
        "        if ICs is not None    : self.new_ICs(ICs)\n",
        "        if params is not None : self.new_params(params)\n",
        "        if t is not None      : self.new_soltimes(t)\n",
        "        if Environ is not None: self.FetchEnviron(Environ)\n",
        "        \n",
        "        # Check if everything needed for a run is now present\n",
        "        if self.params is None or self.y0 is None or self.t is None or self.Env is None:\n",
        "            raise Exception(\"Prequisite data for run is incomplete\")\n",
        "        \n",
        "        # Define the function that is passed to odeint\n",
        "        def deriv(y,t,model):\n",
        "            \n",
        "            # Obtain the environmental data for this value of t\n",
        "            self.Edat\n",
        "            \n",
        "            # Compute required derivatives.  This will entail using data that\n",
        "            # should be ready and waiting in model.par and model.Edat\n",
        "            return model.Eqns(y,t,model)\n",
        "\n",
        "        # Call odeint to itegrate diffeq system.  All the odeint arguments are shown\n",
        "        # here in case we want to modify something in a future version.  (It is, perhaps,\n",
        "        # noteworthy that some of the extra parameters apparenly specify the order of \n",
        "        # integration to be peformed.)\n",
        "\n",
        "        return odeint(deriv,           # Computes the derivative of y at t\n",
        "                      self.y0,         # Initial condition on y (can be a vector) \n",
        "                      self.t,          # The time points for which to solve for y\n",
        "                      args=(self,),    # Extra arguments to pass to function (self reference to\n",
        "                                       #   this model instance)\n",
        "                      Dfun=None,       # Gradient (Jacobian) of func \n",
        "                      col_deriv=0,     # True if Dfun defines derivatives down columns\n",
        "                      full_output=0,   # True if to return a dictionary of \n",
        "                                       #   optional outputs as the second output\n",
        "                      printmessg=0,    # Whether to print the convergence message\n",
        "                      tfirst=False,    # If True, the first two arguments of func \n",
        "                                       #   (and Dfun, if given) must t, y\n",
        "                                \n",
        "        #  See https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.odeint.html\n",
        "        #     ror the definition of these arguments\n",
        "        \n",
        "                      ml=None,           \n",
        "                      mu=None, \n",
        "                      rtol=None, \n",
        "                      atol=None, \n",
        "                      tcrit=None, \n",
        "                      h0=0.0, \n",
        "                      hmax=0.0, \n",
        "                      hmin=0.0, \n",
        "                      ixpr=0, \n",
        "                      mxstep=0, \n",
        "                      mxhnil=0, \n",
        "                      mxordn=12, \n",
        "                      mxords=5)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYVaIq6nSkDG",
        "colab_type": "text"
      },
      "source": [
        "## Defining Simple Wheat Subclass\n",
        "\n",
        "This subclass takes a list of functions/equations as input, and then will use environmental input to keep track of thermal time and other parameters for plant growth.  It will also define rhs which will return a list of functions to be evaluated later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ih30pQySkDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class mark_0_wheat(Model):\n",
        "    def __init__(self,Eqns):\n",
        "        Model.__init__(self,Eqns)\n",
        "        #self.n_var = Model.n_var\n",
        "    def FetchEnviron(self, Environ):\n",
        "        self.start_date = Environ[0]\n",
        "        self.end_date = Environ[1]\n",
        "        file = Environ[2]\n",
        "    \n",
        "        # reading the data\n",
        "        w = pd.read_csv(file)\n",
        "\n",
        "        # change this data into a numpy array to use the where function\n",
        "        day_data = np.asarray(w)\n",
        "    \n",
        "        #find row index of selected start and stop dates, here we choose April 1st through November 11th\n",
        "        start_index = int(np.where(day_data == self.start_date)[0])\n",
        "        stop_index = int(np.where(day_data == self.end_date)[0])\n",
        "\n",
        "        \n",
        "        self.Env = day_data[start_index:stop_index+1, 2:].astype(np.float)\n",
        "        \n",
        "        self.t = np.arange(0,len(self.Env))          \n",
        "        \n",
        "        self.loc_data = self.Env\n",
        "      \n",
        "        self.T_avg  = pchip(self.t,(self.loc_data[:,0] + self.loc_data[:,1])/2)  #average temperature per day (max+min)/2\n",
        "                                                                                 #use the pchip command to interpolate the\n",
        "        self.I = pchip(self.t,(self.loc_data[:,-3])*0.0864)                      #the data since odeint takes noninteger vals\n",
        "        \n",
        "        self.Edat = [self.T_avg, self.I]\n",
        "        \n",
        "        def rhs(self, X, t):\n",
        "            dTT = dtt(X, t) \n",
        "            dLAI = dlai(X, t)\n",
        "            dB = dcho(X, t)       \n",
        "            return np.array([dTT, dLAI, dB])\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjSYCvQ3SkDN",
        "colab_type": "text"
      },
      "source": [
        "### Parameters for simple wheat functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbH_qNvKSkDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "T_base =  0\n",
        "alpha =   5 * 1.0125e-4   #correct alpha values\n",
        "\n",
        "LAImax =  7.0\n",
        "TTL =       21600/24\n",
        "RUE =     1.5\n",
        "#K =       0.7\n",
        "K = 0.2        #correct value\n",
        "\n",
        "TTM =    43200/24\n",
        "#transition_period = 2 #time needed for lai and cho to transition to no growth\n",
        "#lai_transition_tt = 20*transition_period  #thermal time needed for lai transition to no growth\n",
        "#cho_transition_tt = 28*transition_period  #thermal time needed for cho transition to no growth\n",
        "transition_period = 2\n",
        "lai_transition_tt = 20*transition_period\n",
        "cho_transition_tt = 28*transition_period\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbiVbyzZSkDU",
        "colab_type": "text"
      },
      "source": [
        "## Definition of Simple Wheat Functions \n",
        "\n",
        "Summary of changes:\n",
        "\n",
        "We made two major adaptations to these functions and how they work with the model.  The first being that they are now defined outside of RHS and then are passed to RHS; this makes the model class a little more flexible in how it handles functions and smoothed over some type and name space issues we ran into when we first tried to merge our model class with EBT.\n",
        "\n",
        "The second change we made was to simulate the piecewise aspect of dlai and dcho by using tanh as a sort of scaling factor in order to make it differentiable.  Specifically, we now define dlai as \n",
        "$$\\dot{LAI} = \\alpha T_{avg}LAI\\cdot(LAI_{max}-LAI)*\\frac{-1}{2}\\tanh((TT - TTL)/TD_{lai})-1)$$\n",
        "and dcho as \n",
        "$$ \\dot{CHO}(t) = RUE[1-e^{-K\\cdot LAI}]I*\\frac{-1}{2}\\tanh((TT - TTM)/TD_{cho})-1),$$\n",
        "where $TD_{lai}$ and $TD_{cho}$ are thermal days required for the plant to  make the transition to no growth in leaf area index or biomass.  The whole plot was scaled by $\\frac{-1}{2}$ since tanh has a width of two units and is flipped the opposite way from what we needed and shifted by the values $TTL$ and $TTM$ to produce the correct cutoffs.\n",
        "\n",
        "The values needed to scale the inside of tanh were initially key in simply getting a good approximation of the original piecewise functions.  The larger the scale factor, the steeper the transition in tanh, and the more it looks like a piecewise function.  We promptly ran into the issue of a \"RuntimeWarning\" (with the warning citing overflow in power return, double_scalars, sinh, and cosh) for both of these when they were passed to odeint. We believe this was due to the transition being too sharp for autograd to differentiate it. To mitigate this, we began playing around with scaling by progressively smaller numbers in an effort to flatten out the transition to make it possible for autograd to work  with it. By trial and error, it was determined that the scale factor for dlai could be no larger than $\\frac{1}{10}$ and the scale factor for dcho could be no larger than $\\frac{1}{18}$.\n",
        "\n",
        "Eventually, thanks to Dr. Nathan Albin, we realized that these scale factors should make biological sense and reflect the amount of time for the plant to cease growth in these characteristics.  Dr. Stephen Welch suggested going for 2 or 4-5 days.  Since the inside of tanh is in thermal time, these days needed to be converted to \"thermal days\".  To do this, we pinpointed the specific days that the transitions appeared to be taking place, day 57 for dlai and day 90 for dcho, and the rate of change of thermal time on each of those days was approximated using the graph of thermal time below (after running EBT).  Those slopes, 20 for lai and 28 for cho, were then used to compute the thermal transition time for dlai and dcho as shown in the cell above.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvmLwlB1SkDV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Rate of change in Thermal Time\n",
        "def dtt(X, t):\n",
        "    return Sweet.T_avg(t)\n",
        "\n",
        "#Rate of change in Leaf Area Index\n",
        "def dlai(X, t):\n",
        "    TT, LAI, CHO = X\n",
        "    return alpha*Sweet.T_avg(t)*LAI*(LAImax - LAI)*(-1/2)*(np.tanh(((TT-TTL))/lai_transition_tt)-1) \n",
        "  \n",
        "#Rate of change of carbohydrates\n",
        "def dcho(X, t):\n",
        "    TT, LAI, CHO = X\n",
        "    return RUE*(1-np.exp(-K*LAI))*Sweet.I(t)*(-1/2)*(np.tanh((TT-TTM)/cho_transition_tt) - 1)  \n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3_ODcmqSkDe",
        "colab_type": "text"
      },
      "source": [
        "## EBT model class\n",
        "\n",
        "EBT model class takes in the desired model (an instance of Simple Wheat in our case), computes the gradient and hessian for the functions in the model, and then uses population statistics to determine a sort of average solution for the differential equations across possible initial values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxEuBitlSkDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EBTModel:\n",
        "    '''\n",
        "    Simple implementation of an EBT model.\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, model):\n",
        "        '''\n",
        "        Initializes a new EBTModel from a given ODE model.\n",
        "        '''\n",
        "        \n",
        "        self.model = model\n",
        "        self.n_var = model.n_var\n",
        "        self.grad_f = [grad(f) for f in model.Eqns]\n",
        "        self.hess_f = [jacobian(g) for g in self.grad_f]\n",
        "        \n",
        "    def rhs(self, t, X):\n",
        "        '''\n",
        "        The right-hand side function for the SECOND-ORDER EBT approximation.\n",
        "        \n",
        "        The order (t,X) is chosen to support the use of the new scipy.integrate\n",
        "        ODE steppers.\n",
        "        '''\n",
        "        \n",
        "        # initialize derivative vector\n",
        "        deriv = np.zeros(X.shape)\n",
        "\n",
        "        # unpack mu and (flattened) sigma\n",
        "        mu     = X[:self.n_var]\n",
        "        fsigma = X[self.n_var:]\n",
        "        \n",
        "        # unflatten sigma\n",
        "        sigma  = fsigma.reshape(self.n_var,self.n_var)\n",
        "\n",
        "        # evaluate derivatives of means\n",
        "        for i in range(self.n_var):\n",
        "            H = self.hess_f[i](mu, t).flatten()\n",
        "            deriv[i] = self.model.Eqns[i](mu, t) + 0.5*H.dot(fsigma)\n",
        "\n",
        "        # evaluate derivatives of covariance\n",
        "        G = np.array([self.grad_f[i](mu, t) for i in range(self.n_var)])\n",
        "        d_sigma = G.dot(sigma)\n",
        "        d_sigma += d_sigma.T\n",
        "        \n",
        "        # flatten covariance derivatives\n",
        "        deriv[self.n_var:] = d_sigma.flatten()\n",
        "\n",
        "        return deriv"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNWQn9uZSkDq",
        "colab_type": "text"
      },
      "source": [
        "# Running EBT with Simple Wheat\n",
        "\n",
        "We now create an instance of our simple wheat model, which we will call Sweet.  This instance of the model takes in the list of functions \\[dtt, dlai, dcho\\] we defined earlier.  Recall all parameters are defined several cells above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgRdKW1ISkDr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "8ccbe53e-040a-4557-e54d-01b89270cbe4"
      },
      "source": [
        "'''Create instance of simple wheat model'''\n",
        "\n",
        "Sweet=mark_0_wheat([dtt, dlai, dcho]) \n",
        "\n",
        "\n",
        "# Specify the environment to use.  \n",
        "OurEnv = ('2018-04-01','2018-10-01','weather18.csv') \n",
        "Sweet.FetchEnviron(OurEnv)\n",
        "                        \n",
        "t= Sweet.t\n",
        "\n",
        "# Creating instance of Ebt model using the simple wheat model \n",
        "ebt_sweet = EBTModel(Sweet)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-e7cd548fe89e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Specify the environment to use.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mOurEnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'2018-04-01'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'2018-10-01'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'weather18.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mSweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchEnviron\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOurEnv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mSweet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-e2bc2acb9682>\u001b[0m in \u001b[0;36mFetchEnviron\u001b[0;34m(self, Environ)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# reading the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# change this data into a numpy array to use the where function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File weather18.csv does not exist: 'weather18.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy4id_ocSkDw",
        "colab_type": "text"
      },
      "source": [
        "### Creating Initial Values\n",
        "We produce initial values for EBT to use by randomly sampling \"reasonable\" values for mean and covariance for each of Thermal Time, Leaf Area Index, and Carbohydrates.  Then, using those means and covariances, we generate a distribution to then sample 100 potential values, and then use the means and covariances from those samples as our initial value data for EBT later.\n",
        "\n",
        "The initial samplings of the mean are scaled by 0.05 to produce a tighter sampling and then we take the absolute value to guarantee positive values.  A similar strategy was adopted for the covariance, only this time using a scale factor of 0.01.  \n",
        "There is some concern that these scaling factors are resulting in not enough increase in the values of leaf area index in the plots below, though this may also be due to the simplicity of the simple wheat model.  This issue will be discussed in more detail following the direct simulations of the samples for comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHCJL0LqSkDx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# seed the random number generator\n",
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "\n",
        "# number of samples to collect (this is N)\n",
        "n_samples = 100\n",
        "\n",
        "# random mean values for \"populations\" of initial thermal time, leaf area index, and carbohydrates; \n",
        "mu_0 = abs(0.05*np.random.randn(3))\n",
        "mu_0=np.array([0.2,0.02,0.02])\n",
        "\n",
        "\n",
        "# random covariance values for \"populations\" of initial thermal time, leaf area index, and carbohydrates\n",
        "Q, _ = np.linalg.qr(np.random.randn(3,3))\n",
        "sigma_0 = 0.01*Q.dot(np.diag(1 + 10*np.random.rand(3))).dot(Q.T)\n",
        "\n",
        "#sigma_0=np.array([[0.0001, 0.00001,0.00],\n",
        "#             [0.00001,0.0001 ,0.00],\n",
        "#             [0.000  ,0.000  ,1.00]])\n",
        "\n",
        "#sigma_0 = np.array([[0.00, 0.0001, 0.00001],\n",
        "#                    [0.00,0.00001, 0.0001 ],\n",
        "#                    [1.0, 0.000, 0.000]])\n",
        "#\n",
        "\n",
        "sigma_0 = np.array([\n",
        "                    [0.07237154,0,0],[0,0.0001, 0.00001],[0, 0.00001, 0.0001]\n",
        "                    ])\n",
        "# sample the distribution to use to calculate an average and covariance to use for initial values\n",
        "samples = abs(np.random.multivariate_normal(mu_0, sigma_0, n_samples))\n",
        "\n",
        "# gather statistics for initial values\n",
        "mu = np.average(samples, axis=0)\n",
        "sigma = np.cov(samples, rowvar=False)\n",
        "\n",
        "print('target mean = ')\n",
        "print(mu_0)\n",
        "print()\n",
        "print('actual mean =')\n",
        "print(mu)\n",
        "print()\n",
        "print('target covariance =')\n",
        "print(sigma_0)\n",
        "print()\n",
        "print('actual covariance =')\n",
        "print(sigma)\n",
        "print()\n",
        "\n",
        "# replace target values by true values for the test\n",
        "mu_0 = mu\n",
        "sigma_0 = sigma "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G688RWQ6SkD5",
        "colab_type": "text"
      },
      "source": [
        "# Run odeint using second-order EBT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9JEhTuMSkD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define length of time and number of intervals\n",
        "t = np.linspace(0,175, 176)\n",
        "n_t = len(t)\n",
        "\n",
        "# create initial data using means and covariances computed in the cell abov\n",
        "X0 = np.concatenate((mu_0, sigma_0.flatten()))\n",
        "\n",
        "# a trick to swap (t,x) for (x,t) in order to use odeint; also sets up equations for EBT\n",
        "rhs = lambda X,t : ebt_sweet.rhs(t, X)\n",
        "\n",
        "# solve the ODE using second-order EBT with initial values and covariance computed in the cell above, X0\n",
        "x = odeint(rhs, X0, t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXF4puapSkED",
        "colab_type": "text"
      },
      "source": [
        "## Plots for time $(t)$ vs each of TT, LAI, and CHO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFzdvYghSkEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "dcho_xticks = [i*5 for i in range(int(175/5))]\n",
        "    \n",
        "plt.figure(figsize=(16,12))\n",
        "plt.subplot(221)  \n",
        "plt.ylim((0, 5000))\n",
        "plt.plot(t, x[:,0])\n",
        "plt.xlabel('time (day, beginning April 1)')\n",
        "plt.ylabel('Thermal Time')\n",
        "plt.grid(True)\n",
        "#plt.yticks([i*100 for i in range(int(5000/100))])\n",
        "#plt.xticks([i*5 for i in range(int(175/5))])\n",
        "\n",
        "plt.subplot(222)  \n",
        "plt.ylim((0, 1))\n",
        "plt.plot(t, x[:,1])\n",
        "plt.xlabel('time (day, beginning April 1)')\n",
        "plt.ylabel('Leaf Area Index')\n",
        "plt.grid(True)\n",
        "#plt.xticks([i*5 for i in range(int(175/5))])\n",
        "\n",
        "plt.subplot(223)  \n",
        "plt.ylim((0, 80))\n",
        "plt.plot(t, x[:,2])\n",
        "plt.xlabel('time (day, beginning April 1)')\n",
        "plt.ylabel('Biomass')\n",
        "plt.grid(True)\n",
        "#plt.yticks(range(31))\n",
        "#plt.xticks(dcho_xticks)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsaBgPn5SkEN",
        "colab_type": "text"
      },
      "source": [
        "These plots are exact what we expected for thermal time, leaf area index, and biomass.  Thermal time continually increases, the leaf area index stops increasing when the plant matures, as does the biomass. When compared with the plots that contain the piecewise versions of these functions (see homework 5), we see that the use of tanh wound up being a good approximation of the piecewise functions, even with the significant amount of flattening we had to do to avoid an overflow error with odein. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzsMt2deSkEO",
        "colab_type": "text"
      },
      "source": [
        "### Direct simulation of the samples\n",
        "We now evaluate the model at all the initial values we wanted to consider, instead of using a mean of the samples with their covariance to run EBT.\n",
        "\n",
        "The first graph displays LAI for different intitial values and the second shows biomass relative to thermal time for different initial values.  We found it somewhat concerning, biologically, that the lines corresponding to different initial values never cross each other in either graph; this does not seem to reflect reality in that it could be possible for a plant to start with a smaller leaf area index and still wind up being larger than one that started with a larger leaf area index.  We also felt that the leaf area index should have a greater total increase, with the initial increase being quite steep and as time goes on, this increase tapering off, perhaps something similar to a square root or logarithmic function, which could be something to explore for the future.  We had similar thoughts about the biomass plots.\n",
        "\n",
        "As expected, the thermal time plot isn't terribly revealing, since it is drawn from predetermined weather data in the file weather18.csv.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xSO_BJVSkEP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# time range to solve on\n",
        "t_final = 175\n",
        "n_t = 176\n",
        "t = np.linspace(0, t_final, n_t)\n",
        "\n",
        "# storage place for solutions\n",
        "# WARNING: this is just for testing, it wastes a LOT of space\n",
        "X = np.zeros((n_samples, n_t, Sweet.n_var))\n",
        "\n",
        "#swap input values for functions\n",
        "rhs_no_ebt = lambda X,t : np.array([f(X,t) for f in Sweet.Eqns])\n",
        "\n",
        "\n",
        "# find trajectory of each individual\n",
        "from time import perf_counter\n",
        "a = perf_counter()\n",
        "for i in range(n_samples):\n",
        "    X[i,:,:] = odeint(rhs_no_ebt, samples[i,:], t)\n",
        "b = perf_counter()\n",
        "print(\"time for direct\", b-a)\n",
        "\n",
        "    # draw the trajectories\n",
        "plt.figure(figsize=(9,6))\n",
        "plt.plot(X[:,:,0].T, X[:,:,0].T, color='#cccccc', linewidth=0.2);\n",
        "plt.plot(X[:,0,0], X[:,0,0], '.', color='#00aa00', label='initial')\n",
        "plt.plot(X[:,n_t//4,0], X[:,n_t//4,0], '.', color='#0000ff', label='t={:.3f}'.format(t[n_t//4]))\n",
        "plt.plot(X[:,n_t//3,0], X[:,n_t//3,0], '.', color='#ffff00', label='t={:.3f}'.format(t[n_t//3]))\n",
        "plt.plot(X[:,-1,0], X[:,-1,0], '.', color='#ff0000', label='t={:.3f}'.format(t[-1]))\n",
        "plt.legend();\n",
        "\n",
        "    \n",
        "# draw the trajectories\n",
        "plt.figure(figsize=(9,6))\n",
        "plt.plot(X[:,:,0].T, X[:,:,1].T, color='#cccccc', linewidth=0.2);\n",
        "plt.plot(X[:,0,0], X[:,0,1], '.', color='#00aa00', label='initial')\n",
        "plt.plot(X[:,n_t//4,0], X[:,n_t//4,1], '.', color='#0000ff', label='t={:.3f}'.format(t[n_t//4]))\n",
        "plt.plot(X[:,n_t//3,0], X[:,n_t//3,1], '.', color='#ffff00', label='t={:.3f}'.format(t[n_t//3]))\n",
        "plt.plot(X[:,-1,0], X[:,-1,1], '.', color='#ff0000', label='t={:.3f}'.format(t[-1]))\n",
        "plt.legend();\n",
        "\n",
        "# draw the trajectories\n",
        "plt.figure(figsize=(9,6))\n",
        "plt.plot(X[:,:,0].T, X[:,:,2].T, color='#cccccc', linewidth=0.2);\n",
        "plt.plot(X[:,0,0], X[:,0,2], '.', color='#00aa00', label='initial')\n",
        "plt.plot(X[:,n_t//4,0], X[:,n_t//4,2], '.', color='#0000ff', label='t={:.3f}'.format(t[n_t//4]))\n",
        "plt.plot(X[:,n_t//3,0], X[:,n_t//3,2], '.', color='#ffff00', label='t={:.3f}'.format(t[n_t//3]))\n",
        "plt.plot(X[:,-1,0], X[:,-1,2], '.', color='#ff0000', label='t={:.3f}'.format(t[-1]))\n",
        "\n",
        "plt.legend();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbswYeA4SkET",
        "colab_type": "text"
      },
      "source": [
        "These plots show the progression of thermal time, LAI, and biomass with respect to time in days instead of thermal time.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gUQ47Q9SkEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plt.ylim((0,1.0))\n",
        "\n",
        "plt.plot(X[:,:,0].T)\n",
        "plt.show()\n",
        "plt.plot(X[:,:,1].T)\n",
        "plt.show()\n",
        "plt.plot(X[:,:,2].T)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH4WOg1ySkEa",
        "colab_type": "text"
      },
      "source": [
        "# Comparison of first- and second-order EBT with Direct Simulations\n",
        "\n",
        "The first-order EBT approximation is simply $\\dot{\\mu}=f(\\mu,t)$.  It is easy to see, as expected, that first-order EBT does significantly worse than second-order EBT.  Second-order EBT turned out to be stunningly close to the average over the direct simulations, so close in fact we were initially concerned we had somehow duplicated the data. For this reason, the final plot displays the error between second-order EBT and the average over the direct simulations.  As would be expected, the error increases as time goes on, since it builds upon itself.  For LAI and biomass, the error flattens out when those values do as well, again, as expected.\n",
        "\n",
        "It is interesting to note that the error for TT vascillates between positive and negative for a bit, and then  ultimately winds up positive, indicating that EBT tended to wind up overshooting the values, and that for LAI and biomass we see the opposite happening, with consistent underestimation occurring.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy9sxxepSkEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X_avg = np.average(X, axis=0)   #average of direct simulations\n",
        "#X_avg = np.var(X, axis=0)\n",
        "#plot for thermal time\n",
        "plt.figure(figsize=(9,6))\n",
        "plt.plot(t, X_avg[:,0], 'k*', label='direct sim')\n",
        "plt.plot(t, x[:,0], label='2nd order EBT')\n",
        "plt.plot(t, X[0,:,0], label='1st order EBT')\n",
        "plt.legend()\n",
        "plt.title('Thermal Time')\n",
        "plt.xlabel('t')\n",
        "plt.ylabel('T')\n",
        "\n",
        "#plot for leaf area index\n",
        "plt.figure(figsize=(9,6))\n",
        "plt.plot(t, X_avg[:,1], 'k*', label='direct sim')\n",
        "plt.plot(t, x[:,1], label='2nd order EBT')\n",
        "plt.plot(t, X[0,:,1], label='1st order EBT')\n",
        "plt.legend()\n",
        "plt.title('Leaf Area Index')\n",
        "plt.xlabel('t')\n",
        "plt.ylabel('LAI');\n",
        "\n",
        "#plot for biomass\n",
        "plt.figure(figsize=(9,6))\n",
        "plt.plot(t, X_avg[:,2], 'k*', label='direct sim')\n",
        "plt.plot(t, x[:,2], label='2nd order EBT')\n",
        "plt.plot(t, X[0,:,2], label='1st order EBT')\n",
        "plt.legend()\n",
        "plt.title('Biomass')\n",
        "plt.xlabel('t')\n",
        "plt.ylabel('Biomass');\n",
        "\n",
        "plt.figure(figsize = (9,6))\n",
        "plt.plot(t, x[:,0] - X_avg[:,0], 'bo', label = 'error?')\n",
        "plt.legend()\n",
        "plt.title('difference in direct simulation and 2nd order EBT for TT')\n",
        "plt.xlabel('t')\n",
        "plt.ylabel('T T')\n",
        "\n",
        "plt.figure(figsize = (9,6))\n",
        "plt.plot(t, x[:,1] - X_avg[:,1], 'bo', label = 'error?')\n",
        "plt.legend()\n",
        "plt.title('difference in direct simulation and 2nd order EBT for LAI')\n",
        "plt.xlabel('t')\n",
        "plt.ylabel('T T')\n",
        "\n",
        "plt.figure(figsize = (9,6))\n",
        "plt.plot(t, x[:,2] - X_avg[:,2], 'bo', label = 'error?')\n",
        "plt.legend()\n",
        "plt.title('difference in direct simulation and 2nd order EBT for Biomass')\n",
        "plt.xlabel('t')\n",
        "plt.ylabel('T T')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4TIqm2dHzQM",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "LAI vs Biomass plot for 2nd Order EBT Simulation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkMMXiPTSkEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot for leaf on horizontal  vs biomass on vertical \n",
        "T = np.arange(176)\n",
        "plt.figure(figsize=(9,6))\n",
        "#plt.plot(X_avg[:,1], X_avg[:,2], 'r', label='direct sim')\n",
        "#plt.plot(X[:,:,1].T, X[:,:,2].T, )\n",
        "plt.plot(x[:,1], x[:,2],'k*', label='2nd order EBT')\n",
        "plt.legend()\n",
        "plt.title('Leaf area index vs Biomass')\n",
        "plt.xlabel('leaf area index')\n",
        "plt.ylabel('Biomass');\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMTy70ydaDyc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_var = np.var(X, axis=0)\n",
        "T = np.arange(176)\n",
        "plt.figure(figsize=(9,6))\n",
        "plt.plot(X_var[:,1], X_var[:,2], 'r', label='variance')\n",
        "plt.plot(X[:,:,1].T, X[:,:,2].T, )\n",
        "plt.plot(x[:,1], x[:,2],'k*', label='2nd order EBT')\n",
        "plt.plot(x[:,7], x[:,11], 'k*',label='test')\n",
        "plt.legend()\n",
        "plt.title('Leaf area index vs Biomass')\n",
        "plt.xlabel('leaf area index')\n",
        "plt.ylabel('Biomass');\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L72kF3zOtoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot for leaf on horizontal  vs biomass on vertical \n",
        "\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.collections import LineCollection\n",
        "T = np.arange(176)\n",
        "def plot_colourline(x,y,c, w=1):\n",
        "    c = cm.jet((c-np.min(c))/(np.max(c)-np.min(c)))\n",
        "    ax = plt.gca()\n",
        "    for i in np.arange(len(x)-1):\n",
        "        ax.plot([x[i],x[i+1]], [y[i],y[i+1]], c=c[i], lw = w)\n",
        "    return c\n",
        "\n",
        "def plot_colourline2(x,y,c, w=1):\n",
        "    c = cm.jet((c-np.min(c))/(np.max(c)-np.min(c)))\n",
        "    ax = plt.gca()\n",
        "    for i in np.arange(len(x)-1):\n",
        "        ax.plot([x[i],x[i+1]], [y[i],y[i+1]], c=c[i], lw = w)\n",
        "    return c\n",
        "plt.figure(figsize=(9,6))\n",
        "plot_colourline(X[:,:,1].T, X[:,:,2].T, T)\n",
        "plot_colourline2(x[:,1], x[:,2],T, w=5)\n",
        "\n",
        "\n",
        "#plt.plot(X[:,:,1].T, X[:,:,2].T, label = \"Direct simulation\")\n",
        "#plt.plot(x[:,1], x[:,2],'k*',c =c, label='2nd order EBT')\n",
        "plt.legend()\n",
        "plt.title('Leaf area index vs Biomass')\n",
        "plt.xlabel('leaf area index')\n",
        "plt.ylabel('Biomass');\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P538gQzJtZis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot_colourline3(x,y,c, w=1):\n",
        "    #c = cm.jet((c-np.min(c))/(np.max(c)-np.min(c)))\n",
        "    ax = plt.gca()\n",
        "    for i in np.arange(len(x)-1):\n",
        "        ax.plot([x[i],x[i+1]], [y[i],y[i+1]], c=cm.jet(normalize(i*1.5)), lw = w)\n",
        "    return c\n",
        "\n",
        "def plot_colourline4(x,y,c, w=10):\n",
        "    c = cm.cool((c-np.min(c))/(np.max(c)-np.min(c)))\n",
        "    ax = plt.gca()\n",
        "    for i in np.arange(len(x)-1):\n",
        "        ax.plot([x[i],x[i+1]], [y[i],y[i+1]], c=cm.cool(normalize(i*1.5)), lw = w)\n",
        "    return c\n",
        "def plot_colourline4dash(x,y,c, w=1):\n",
        "    c = cm.cool((c-np.min(c))/(np.max(c)-np.min(c)))\n",
        "    ax = plt.gca()\n",
        "    for i in np.arange(len(x)-1):\n",
        "        ax.plot([x[i],x[i+1]], [y[i],y[i+1]], c=cm.Greys_r(normalize(i*1.5)), marker='o', lw = w)\n",
        "    return c\n",
        "\n",
        "\n",
        "#VARIANCE PLOTS FUNCTIONS     \n",
        "def plot_colourline5(x,y,c, w=1):\n",
        "    c = cm.ocean((c-np.min(c))/(np.max(c)-np.min(c)))\n",
        "    ax = plt.gca()\n",
        "    for i in np.arange(len(x)-1):\n",
        "        ax.plot([x[i],x[i+1]], [y[i],y[i+1]], c=cm.ocean(normalize(i*1.5)), lw = w)\n",
        "    return c   \n",
        "def plot_colourline6(x,y,c, w=1):\n",
        "    c = cm.gist_earth((c-np.min(c))/(np.max(c)-np.min(c)))\n",
        "    ax = plt.gca()\n",
        "    for i in np.arange(len(x)-1):\n",
        "        ax.plot([x[i],x[i+1]], [y[i],y[i+1]], c=cm.Reds(normalize(i*1.5)), marker=11, lw = w)\n",
        "    return c\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0iynb2hslf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def coloured_linePlotter(x,y,c, w=1, marker=None, colorofline = cm.Reds, markersize=None):\n",
        "    c = cm.gist_earth((c-np.min(c))/(np.max(c)-np.min(c)))\n",
        "    ax = plt.gca()\n",
        "    for i in np.arange(len(x)-1):\n",
        "        ax.plot([x[i],x[i+1]], [y[i],y[i+1]], c=colorofline(normalize(i*1.5)), marker=marker, lw = w, markersize=markersize)\n",
        "    return c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5HBTk24GoZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib\n",
        "plt.rcParams.update({'font.size': 12})\n",
        "normalize = matplotlib.colors.Normalize(vmin=1, vmax=175)\n",
        "norm = matplotlib.colors.Normalize(vmin=1, vmax=175)\n",
        "X_avg = np.average(X, axis=0) \n",
        "X_var = np.var(X, axis=0)\n",
        "fig = plt.figure(figsize=(9, 6))\n",
        "plot_colourline3(X[:,:,1].T, X[:,:,2].T, T)\n",
        "plot_colourline4(x[:,1], x[:,2],T)\n",
        "plot_colourline4dash(X_avg[:,1].T, X_avg[:,2].T, T)\n",
        "plot_colourline5(X_var[:, 1], X_var[:, 2], T, w = 10)\n",
        "plot_colourline6(x[:, 7], x[:, 11], T)\n",
        "\n",
        "# coloured_linePlotter(X[:,:,1].T, X[:,:,2].T, T, w=1, colorofline = cm.jet, )\n",
        "# coloured_linePlotter(x[:,1], x[:,2],T, w=10, colorofline=cm.cool)\n",
        "# coloured_linePlotter(X_avg[:,1].T, X_avg[:,2].T, T, w=1, colorofline = cm.Greys_r, marker = 'o')\n",
        "# coloured_linePlotter(X_var[:, 1], X_var[:, 2], T, w = 10, colorofline= cm.ocean)\n",
        "# coloured_linePlotter(x[:, 7], x[:, 11], T, w=1, colorofline = cm.Reds, marker = 11)\n",
        "\n",
        "import matplotlib.patches as mpatches\n",
        "plt.title('Mean and variance plots of LAI vs Biomass')\n",
        "plt.xlabel('Leaf Area Index')\n",
        "plt.ylabel('Biomass');\n",
        "plt.savefig(\"final.png\", dpi = 300)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytURHf-AnRQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.rcParams.update({'font.size': 12})\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "fig, ax = plt.subplots(5,figsize=(6,6) )\n",
        "\n",
        "norm = mpl.colors.Normalize(vmin=1, vmax=175)\n",
        "cb1 = mpl.colorbar.ColorbarBase(ax[0], cmap=mpl.cm.jet,\n",
        "                                norm=norm,\n",
        "                                orientation='horizontal')\n",
        "cb1.set_label('Time (days) - Population Direct Simulations')\n",
        "cb2 = mpl.colorbar.ColorbarBase(ax[1], cmap=mpl.cm.cool,\n",
        "                                norm=norm,\n",
        "                                orientation='horizontal')\n",
        "\n",
        "cb2.set_label('Time (days) -  Population Direct Simulation Mean')\n",
        "cb3 = mpl.colorbar.ColorbarBase(ax[2], cmap=mpl.cm.Greys_r,\n",
        "                                norm=norm,\n",
        "                                orientation='horizontal')\n",
        "cb3.set_label('Time (days) - 2nd Order EBT Mean')\n",
        "cb4 = mpl.colorbar.ColorbarBase(ax[3], cmap=mpl.cm.ocean,\n",
        "                                norm=norm,\n",
        "                                orientation='horizontal')\n",
        "\n",
        "cb4.set_label('Time(Days) - Population Direct Simulation Variance')\n",
        "cb5 = mpl.colorbar.ColorbarBase(ax[4], cmap=mpl.cm.Reds,\n",
        "                                norm=norm,\n",
        "                                orientation='horizontal')\n",
        "\n",
        "cb5.set_label('Time(days) - 2nd Order EBT variance')\n",
        "plt.tight_layout()\n",
        "fig.show()\n",
        "plt.savefig('colorabars.png', dpi=300)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrF0blUeu-mt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib\n",
        "plt.rcParams.update({'font.size': 12})\n",
        "normalize = matplotlib.colors.Normalize(vmin=1, vmax=175)\n",
        "norm = matplotlib.colors.Normalize(vmin=1, vmax=175)\n",
        "X_var = np.var(X, axis=0)\n",
        "fig = plt.figure(figsize=(9, 6))\n",
        "\n",
        "coloured_linePlotter(X_avg[:,1].T, X_avg[:,2].T, T, w=2, colorofline = cm.jet, marker = '>', markersize=5)\n",
        "coloured_linePlotter(x[:,1], x[:,2],T, w=2, colorofline=cm.cool)\n",
        "\n",
        "\n",
        "#varinces\n",
        "coloured_linePlotter(X_var[:, 1], X_var[:, 2], T, w = 2, colorofline= cm.jet, marker = '>', markersize=5)\n",
        "coloured_linePlotter(x[:, 7], x[:, 11], T, w=2, colorofline = cm.cool)\n",
        "\n",
        "import matplotlib.patches as mpatches\n",
        "plt.title('Mean and variance plots of LAI vs Biomass')\n",
        "plt.xlabel('Leaf Area Index')\n",
        "plt.ylabel('Biomass');\n",
        "plt.savefig(\"final.png\", dpi = 300)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxj737_b2cy7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.rcParams.update({'font.size': 12})\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "\n",
        "fig, ax = plt.subplots(4,figsize=(6,5) )\n",
        "\n",
        "norm = mpl.colors.Normalize(vmin=1, vmax=175)\n",
        "\n",
        "\n",
        "cb1 = mpl.colorbar.ColorbarBase(ax[0], cmap=mpl.cm.jet,\n",
        "                                norm=norm,\n",
        "                                orientation='horizontal')\n",
        "cb1.set_label('Time (days) -  Population Direct Simulation Mean')\n",
        "\n",
        "cb2 = mpl.colorbar.ColorbarBase(ax[1], cmap=mpl.cm.cool,\n",
        "                                norm=norm,\n",
        "                                orientation='horizontal')\n",
        "cb2.set_label('Time (days) - 2nd Order EBT Mean')\n",
        "\n",
        "cb3 = mpl.colorbar.ColorbarBase(ax[2], cmap=mpl.cm.jet,\n",
        "                                norm=norm,\n",
        "                                orientation='horizontal')\n",
        "cb3.set_label('Time(Days) - Population Direct Simulation Variance')\n",
        "\n",
        "cb4 = mpl.colorbar.ColorbarBase(ax[3], cmap=mpl.cm.cool,\n",
        "                                norm=norm,\n",
        "                                orientation='horizontal')\n",
        "\n",
        "cb4.set_label('Time(days) - 2nd Order EBT variance')\n",
        "plt.tight_layout()\n",
        "fig.show()\n",
        "plt.savefig('colorabars.png', dpi=300)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZUUfv1UXYam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = x\n",
        "p = []\n",
        "for i in range(len(k)):\n",
        "  p.append(k[i][3:12])\n",
        "detty = []\n",
        "for i in range(len(p)):\n",
        "  detty.append(np.linalg.det(p[i].reshape((3,3))))\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.plot(detty)\n",
        "plt.xlabel(\"time\")\n",
        "plt.ylabel(\"det\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nwUpZHNd-it",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x[0:175, 0:9][0]\n",
        "a = x\n",
        "p = []\n",
        "detty = []\n",
        "for i in range(len(a)):\n",
        "  detty.append(np.linalg.det(a[:, 3:12][i].reshape((3,3))))\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.plot(detty)\n",
        "plt.yscale('log')\n",
        "plt.xlabel(\"time\")\n",
        "plt.ylabel(\"det\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8TP17ppW6fy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#saving numpy array\n",
        "with open('original.npy', 'wb') as f:\n",
        "    np.save(f, x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CHnyLGUV1Ra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x[0:175, 0:9][0]\n",
        "a = np.load('original.npy')\n",
        "# b = np.load('diverging.npy') \n",
        "b = x\n",
        "p = []\n",
        "q = []\n",
        "detty = []\n",
        "detty2 = []\n",
        "for i in range(len(a)):\n",
        "  detty.append(np.linalg.det(a[:, 3:12][i].reshape((3,3))))\n",
        "for i in range(len(b)):\n",
        "  detty2.append(np.linalg.det(b[:, 3:12][i].reshape((3,3))))\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.plot(detty, label = 'original parametres')\n",
        "plt.plot(detty2, label = \"diverging parametres\")\n",
        "plt.legend()\n",
        "plt.yscale('log')\n",
        "plt.xlabel(\"time\")\n",
        "plt.ylabel(\"det\")\n",
        "plt.savefig('detcompare.png', dpi=300)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS-LmGSXj5wJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib\n",
        "plt.rcParams.update({'font.size': 12})\n",
        "normalize = matplotlib.colors.Normalize(vmin=1, vmax=175)\n",
        "norm = matplotlib.colors.Normalize(vmin=1, vmax=175)\n",
        "X_var = np.var(X, axis=0)\n",
        "fig = plt.figure(figsize=(9, 6))\n",
        "\n",
        "coloured_linePlotter(X_avg[:,1].T, X_avg[:,2].T, T, w=2, colorofline = cm.jet, marker = '>', markersize=5)\n",
        "coloured_linePlotter(x[:,1], x[:,2],T, w=2, colorofline=cm.cool)\n",
        "\n",
        "\n",
        "#varinces\n",
        "coloured_linePlotter(X_var[:, 1], X_var[:, 2], T, w = 2, colorofline= cm.jet, marker = '>', markersize=5)\n",
        "coloured_linePlotter(x[:, 7], x[:, 11], T, w=2, colorofline = cm.cool)\n",
        "\n",
        "import matplotlib.patches as mpatches\n",
        "plt.title('Mean and variance plots of LAI vs Biomass')\n",
        "plt.xlabel('Leaf Area Index')\n",
        "plt.ylabel('Biomass');\n",
        "plt.twinx()\n",
        "plt.ylabel('det')\n",
        "plt.twiny()\n",
        "plt.xlabel('time')\n",
        "# plt.plot(detty2, label= \"original paramenters\", color = \"k\")\n",
        "coloured_linePlotter(T, detty2, T, w=2, colorofline = cm.jet)\n",
        "plt.legend()\n",
        "plt.yscale('log')\n",
        "#plt.plot(detty2, label= \"diverging parametres paramenters\", 'b')\n",
        "plt.savefig(\"final.png\", dpi = 300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gLPcm3NMBls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x[0:175, 0:9][0]\n",
        "a = np.load('original.npy')\n",
        "# b = np.load('diverging.npy') \n",
        "b = x\n",
        "p = []\n",
        "q = []\n",
        "condy = []\n",
        "condy2 = []\n",
        "time = perf_counter()\n",
        "for i in range(len(a)):\n",
        "  condy.append(np.linalg.cond(a[:, 3:12][i].reshape((3,3))))\n",
        "print(\"for condition number\", (perf_counter()-time)/len(x))\n",
        "for i in range(len(b)):\n",
        "  condy2.append(np.linalg.cond(b[:, 3:12][i].reshape((3,3))))\n",
        "\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.plot(condy, label = 'original parametres')\n",
        "plt.plot(condy2, label = \"diverging parametres\")\n",
        "plt.legend()\n",
        "plt.yscale('log')\n",
        "plt.xlabel(\"time\")\n",
        "plt.ylabel(\"Condition Number\")\n",
        "plt.savefig('condcompare.png', dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqUiUl6hMCxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib\n",
        "plt.rcParams.update({'font.size': 12})\n",
        "normalize = matplotlib.colors.Normalize(vmin=1, vmax=175)\n",
        "norm = matplotlib.colors.Normalize(vmin=1, vmax=175)\n",
        "X_var = np.var(X, axis=0)\n",
        "fig = plt.figure(figsize=(9, 6))\n",
        "\n",
        "coloured_linePlotter(X_avg[:,1].T, X_avg[:,2].T, T, w=2, colorofline = cm.jet, marker = '>', markersize=5)\n",
        "coloured_linePlotter(x[:,1], x[:,2],T, w=2, colorofline=cm.jet)\n",
        "\n",
        "\n",
        "#varinces\n",
        "coloured_linePlotter(X_var[:, 1], X_var[:, 2], T, w = 2, colorofline= cm.jet, marker = '>', markersize=5)\n",
        "coloured_linePlotter(x[:, 7], x[:, 11], T, w=2, colorofline = cm.jet)\n",
        "\n",
        "import matplotlib.patches as mpatches\n",
        "plt.title('Mean and variance plots of LAI vs Biomass')\n",
        "plt.xlabel('Leaf Area Index')\n",
        "plt.ylabel('Biomass');\n",
        "plt.twinx()\n",
        "plt.ylabel('Condition Number')\n",
        "plt.twiny()\n",
        "plt.xlabel('time')\n",
        "# plt.plot(detty2, label= \"original paramenters\", color = \"k\")\n",
        "coloured_linePlotter(T, condy2, T, w=2, colorofline = cm.jet)\n",
        "\n",
        "plt.yscale('log')\n",
        "#plt.plot(detty2, label= \"diverging parametres paramenters\", 'b')\n",
        "plt.savefig(\"final.png\", dpi = 300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msU-NefePWo9",
        "colab_type": "text"
      },
      "source": [
        "Creating own color bar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNzOvQofPB64",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib\n",
        "plt.rcParams.update({'font.size': 12})\n",
        "normalize = matplotlib.colors.Normalize(vmin=1, vmax=175)\n",
        "norm = matplotlib.colors.Normalize(vmin=1, vmax=175)\n",
        "X_var = np.var(X, axis=0)\n",
        "fig = plt.figure(figsize=(9, 6))\n",
        "def black_redcolourbar(x,y,c, w=1, marker=None, colorofline = cm.Reds, markersize=None):\n",
        "    c = cm.Greys((c-np.min(c))/(np.max(c)-np.min(c)))\n",
        "    ax = plt.gca()\n",
        "    for i in np.arange(len(x)-1):\n",
        "        ax.plot([x[i],x[i+1]], [y[i],y[i+1]], c=c[175] if i!=40 else (1,0,0,1), marker=marker, lw = 3, markersize=markersize)\n",
        "    return c\n",
        "\n",
        "black_redcolourbar(X_avg[:,1].T, X_avg[:,2].T, T, w=2, colorofline = cm.jet, marker = '>', markersize=5)\n",
        "coloured_linePlotter(x[:,1], x[:,2],T, w=2, colorofline=cm.jet)\n",
        "\n",
        "\n",
        "#varinces\n",
        "black_redcolourbar(X_var[:, 1], X_var[:, 2], T, w = 2, colorofline= cm.jet, marker = '>', markersize=5)\n",
        "black_redcolourbar(x[:, 7], x[:, 11], T, w=2, colorofline = cm.jet)\n",
        "\n",
        "import matplotlib.patches as mpatches\n",
        "plt.title('Mean and variance plots of LAI vs Biomass')\n",
        "plt.xlabel('Leaf Area Index')\n",
        "plt.ylabel('Biomass');\n",
        "plt.axis([0, 2, 0, 100])\n",
        "plt.twinx()\n",
        "plt.ylabel('Condition Number')\n",
        "plt.twiny()\n",
        "plt.xlabel('time')\n",
        "# plt.plot(detty2, label= \"original paramenters\", color = \"k\")\n",
        "black_redcolourbar(T, condy2, T, w=2, colorofline = cm.jet)\n",
        "plt.yscale('log')\n",
        "#plt.plot(detty2, label= \"diverging parametres paramenters\", 'b')\n",
        "plt.savefig(\"conditionNumber.png\", dpi = 300)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fzZQEASEkFk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x[0:175, 0:9][0]\n",
        "a = np.load('original.npy')\n",
        "# b = np.load('diverging.npy') \n",
        "b = x\n",
        "p = []\n",
        "q = []\n",
        "Frobenius = []\n",
        "Frobenius2  = []\n",
        "time = perf_counter()\n",
        "for i in range(len(a)):\n",
        "  Frobenius.append(np.linalg.norm(a[:, 3:12][i].reshape((3,3)), ord='fro'))\n",
        "print(\"for Frobenius number\", (perf_counter()-time)/len(x))\n",
        "for i in range(len(b)):\n",
        "  Frobenius2.append(np.linalg.norm(b[:, 3:12][i].reshape((3,3)), ord='fro'))\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.plot(Frobenius , label = 'original parametres')\n",
        "plt.plot(Frobenius2 , label = \"diverging parametres\")\n",
        "plt.legend()\n",
        "# plt.yscale('log')\n",
        "plt.xlabel(\"time\")\n",
        "plt.ylabel(\"Frobenius norm\")\n",
        "plt.savefig('Frobeniusnorm.png', dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHjMdB6-Fk3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib\n",
        "plt.rcParams.update({'font.size': 12})\n",
        "normalize = matplotlib.colors.Normalize(vmin=1, vmax=175)\n",
        "norm = matplotlib.colors.Normalize(vmin=1, vmax=175)\n",
        "X_var = np.var(X, axis=0)\n",
        "fig = plt.figure(figsize=(9, 6))\n",
        "\n",
        "black_redcolourbar(X_avg[:,1].T, X_avg[:,2].T, T, w=2, colorofline = cm.prism, marker = '>', markersize=5)\n",
        "coloured_linePlotter(x[:,1], x[:,2],T, w=2, colorofline=cm.jet)\n",
        "\n",
        "\n",
        "#varinces\n",
        "black_redcolourbar(X_var[:, 1], X_var[:, 2], T, w = 2, colorofline= cm.prism, marker = '>', markersize=5)\n",
        "black_redcolourbar(x[:, 7], x[:, 11], T, w=2, colorofline = cm.jet)\n",
        "\n",
        "import matplotlib.patches as mpatches\n",
        "plt.title('Mean and variance plots of LAI vs Biomass')\n",
        "plt.xlabel('Leaf Area Index')\n",
        "plt.ylabel('Biomass');\n",
        "plt.axis([0,2,0,100])\n",
        "plt.twinx()\n",
        "plt.ylabel('Frobenius Norm')\n",
        "plt.twiny()\n",
        "plt.xlabel('time')\n",
        "black_redcolourbar(T, Frobenius2, T, w=2, colorofline = cm.jet)\n",
        "# plt.yscale('log')\n",
        "plt.savefig(\"Frobenius.png\", dpi = 300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agld1UV5GLM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x[0:175, 0:9][0]\n",
        "a = np.load('original.npy')\n",
        "# b = np.load('diverging.npy') \n",
        "b = x\n",
        "p = []\n",
        "q = []\n",
        "secondnorm = []\n",
        "secondnorm2  = []\n",
        "time = perf_counter()\n",
        "for i in range(len(a)):\n",
        "  secondnorm.append(np.linalg.norm(a[:, 3:12][i].reshape((3,3)), ord=2))\n",
        "print(\"for 2nd number\", (perf_counter()-time)/len(a))\n",
        "for i in range(len(b)):\n",
        "  secondnorm2.append(np.linalg.norm(b[:, 3:12][i].reshape((3,3)), ord=2))\n",
        "plt.figure(figsize=(9, 6))\n",
        "plt.plot(secondnorm , label = 'original parametres')\n",
        "plt.plot(secondnorm2 , label = \"diverging parametres\")\n",
        "plt.legend()\n",
        "# plt.yscale('log')\n",
        "plt.xlabel(\"time\")\n",
        "plt.ylabel(\"second norm\")\n",
        "plt.savefig('secondnorm.png', dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4_oD7gLHVts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib\n",
        "plt.rcParams.update({'font.size': 12})\n",
        "normalize = matplotlib.colors.Normalize(vmin=1, vmax=175)\n",
        "norm = matplotlib.colors.Normalize(vmin=1, vmax=175)\n",
        "X_var = np.var(X, axis=0)\n",
        "fig = plt.figure(figsize=(9, 6))\n",
        "\n",
        "black_redcolourbar(X_avg[:,1].T, X_avg[:,2].T, T, w=2, colorofline = cm.jet, marker = '>', markersize=5)\n",
        "coloured_linePlotter(x[:,1], x[:,2],T, w=2, colorofline=cm.jet)\n",
        "\n",
        "\n",
        "#varinces\n",
        "black_redcolourbar(X_var[:, 1], X_var[:, 2], T, w = 2, colorofline= cm.jet, marker = '>', markersize=5)\n",
        "black_redcolourbar(x[:, 7], x[:, 11], T, w=2, colorofline = cm.jet)\n",
        "\n",
        "import matplotlib.patches as mpatches\n",
        "plt.title('Mean and variance plots of LAI vs Biomass')\n",
        "plt.xlabel('Leaf Area Index')\n",
        "plt.ylabel('Biomass');\n",
        "plt.axis([0,2,0,100])\n",
        "plt.twinx()\n",
        "plt.ylabel('2- Norm')\n",
        "plt.twiny()\n",
        "plt.xlabel('time')\n",
        "black_redcolourbar(T, secondnorm2, T, w=2, colorofline = cm.jet)\n",
        "# plt.yscale('log')\n",
        "plt.savefig(\"2-norm.png\", dpi = 300)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q8HAa1XU39U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sobol_seq.i4_bit_hi1\n",
        "# sobol_seq.i4_bit_lo0\n",
        "# sobol_seq.i4_sobol\n",
        "# sobol_seq.i4_sobol_generate\n",
        "# sobol_seq.i4_sobol_generate_std_normal\n",
        "# sobol_seq.i4_uniform\n",
        "# sobol_seq.prime_ge\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67sr5cV4VMuM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s2 = sobol_seq.i4_sobol_generate(2, 100)\n",
        "\n",
        "sobol_X, sobol_Y = s2[:, 0], s2[:, 1]\n",
        "\n",
        "sobol_X2 = (np.array(sobol_X) + np.random.uniform())%1\n",
        "sobol_Y2 = (np.array(sobol_Y) + np.random.uniform())%1\n",
        "\n",
        "SX = np.random.uniform(size=(100*2))\n",
        "\n",
        "f, (ax1, ax2, ax3) = plt.subplots(ncols=3, figsize=(12,4))\n",
        "ax1.scatter(SX[:100], SX[100:])\n",
        "ax2.scatter(sobol_X, sobol_Y, color=\"red\")\n",
        "ax3.scatter(sobol_X2, sobol_Y2, color=\"green\")\n",
        "\n",
        "ax1.set_title(\"Random\")\n",
        "ax2.set_title(\"Sobol\")\n",
        "ax3.set_title(\"Sobol again\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dWIiBeOGOvh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rs =[a.reshape(3,3) for a in x[:, 3:12]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9heugvE8LXA5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vals= np.linalg.eigvals(rs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrzQDf1kOSqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sympy\n",
        "a = sympy.Matrix(rs[0])\n",
        "a.eigenvects()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbDZ0hoHrKXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize =(9, 6))\n",
        "plt.plot(vals[:, 0], label = '1st')\n",
        "plt.plot(vals[:, 1], label = '2nd')\n",
        "plt.plot(vals[:, 2] , label = '3rd')\n",
        "plt.yscale('log')\n",
        "plt.legend()\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('eigenvalues')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWRrotMRU-Ek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.all(np.linalg.eigvals(rs) > 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9mHJ-rvzZcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(x[:, 3], label = 'TT')\n",
        "plt.plot(x[:, 7], label =\"LAI\")\n",
        "plt.plot(x[:, 11], label='biomass')\n",
        "plt.legend()\n",
        "plt.yscale(\"log\")\n",
        "plt.xlabel(\"time\")\n",
        "plt.ylabel(\"covaraince\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRQFYukfgND_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(x[:, 0], label = 'TT')\n",
        "plt.plot(x[:, 1], label =\"LAI\")\n",
        "plt.plot(x[:, 2], label='biomass')\n",
        "plt.legend()\n",
        "plt.yscale(\"log\")\n",
        "plt.xlabel(\"time\")\n",
        "plt.ylabel(\"mean\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-CX9vXTwqOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def series_of_points(vals):\n",
        "  alpha = 0.1\n",
        "  beta = 0.1\n",
        "  gamma = 0.1\n",
        "  Rx = []\n",
        "  Ry = []\n",
        "  Rz = []\n",
        "  lams = []\n",
        "  temp = []\n",
        "  lamdot = []\n",
        "  for t in range(len(vals)):\n",
        "    Rx.append(np.array([[np.cos(alpha*t), -np.sin(alpha * t), 0], [np.sin(alpha*t), np.cos(alpha*t), 0], [0, 0, 1]]))\n",
        "    Ry.append(np.array([[np.cos(beta*t), 0, np.sin(beta*t)], [0, 1, 0], [-np.sin(beta*t), 0, np.cos(beta*t)]]))\n",
        "    Rz.append(np.array([[1, 0, 0], [0, np.cos(gamma*t), - np.sin(gamma*t)], [0, np.sin(gamma*t), np.cos(gamma*t)]]))\n",
        "    lamdot.append(np.diag(vals[t]))\n",
        "  return Rx, Ry, Rz, lamdot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9TkTNuuW84O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Rx, Ry, Rz, lamdot = series_of_points(vals)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djhs5jur2ywY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "b = np.array([[1, 1, 1]])\n",
        "Rdot = np.matmul(np.matmul(Rx, Ry), Rz)\n",
        "A= []\n",
        "for rdot, l in zip(Rdot, lamdot):\n",
        "  A.append(np.matmul(np.matmul(rdot,l), rdot.T))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfPxFzAP5Dum",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "points = []\n",
        "for a in A:\n",
        "  points.append(np.matmul(b, a)[0])\n",
        "p = np.array(points)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsymG823zcPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%matplotlib notebook\n",
        "import matplotlib as mpl\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import gridspec\n",
        "colo = []\n",
        "mpl.rcParams['legend.fontsize'] = 10\n",
        "fig = plt.figure(figsize=(9, 6))\n",
        "G = gridspec.GridSpec(1, 2, width_ratios=[10, 1])\n",
        "ax1 = fig.add_subplot(G[0:2,0], projection='3d')\n",
        "for i in range(len(p) - 1):\n",
        "  ax1.plot3D(p[i:i+2,0], p[i:i+2, 1], p[i:i+2, 2], c=cm.Reds(normalize(i)))\n",
        "ax2 = fig.add_subplot(G[0,1])\n",
        "cb1 = mpl.colorbar.ColorbarBase(ax2, cmap=cm.Reds,\n",
        "                                 norm=norm,\n",
        "                                 orientation='vertical')\n",
        "cb1.set_label('time')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IwBDqXPzsox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.spatial.transform import Rotation as R\n",
        "bunchofR = []\n",
        "for i in range(len(vals)):\n",
        "  r = R.from_quat([0, 0, np.sin(100*i), np.cos(100*i)])\n",
        "  bunchofR.append(r.as_matrix())\n",
        "A= []\n",
        "for r, l in zip(bunchofR, lamdot):\n",
        "  A.append(np.matmul(np.matmul(r,l), r.T))\n",
        "points = []\n",
        "for a in A:\n",
        "  points.append(np.matmul(b, a)[0])\n",
        "p2 = np.array(points)\n",
        "import matplotlib as mpl\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import gridspec\n",
        "colo = []\n",
        "for k in range(len(vals)):\n",
        "  colo.append(cm.Greens(normalize(k)))\n",
        "mpl.rcParams['legend.fontsize'] = 10\n",
        "fig = plt.figure(figsize=(9, 6))\n",
        "G = gridspec.GridSpec(6, 2, width_ratios=[10, 1])\n",
        "ax1 = fig.add_subplot(G[:,0], projection='3d')\n",
        "ax1.scatter3D(p2[:,0], p2[:, 1], p2[:, 2])\n",
        "#ax1.plot(p2[:,0], p2[:, 1], p2[:, 2])\n",
        "ax2 = fig.add_subplot(G[1:6,1])\n",
        "\n",
        "cb1 = mpl.colorbar.ColorbarBase(ax2, cmap=cm.Greens,\n",
        "                                 norm=norm,\n",
        "                                 orientation='vertical')\n",
        "cb1.set_label('time')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfSV-0aDXinl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def angular_velocity(alpha, beta, gamma, vals):\n",
        "  s = []\n",
        "  for t in range(len(vals)):\n",
        "    Rx = np.array([[np.cos(alpha*t), -np.sin(alpha * t), 0],\n",
        "                   [np.sin(alpha*t), np.cos(alpha*t), 0], \n",
        "                   [0, 0, 1]])\n",
        "    Ry = np.array([[np.cos(beta*t), 0, np.sin(beta*t)],\n",
        "                   [0, 1, 0], \n",
        "                   [-np.sin(beta*t), 0, np.cos(beta*t)]])\n",
        "    Rz = np.array([[1, 0, 0], \n",
        "                   [0, np.cos(gamma*t), - np.sin(gamma*t)], \n",
        "                   [0, np.sin(gamma*t), np.cos(gamma*t)]]) \n",
        "    Rxdot = np.array([[-np.sin(alpha *t)*alpha , -np.cos(alpha*t)*alpha , 0], \n",
        "                      [np.cos(alpha*t)*alpha, -np.sin(alpha*t)*alpha, 0], \n",
        "                      [0, 0, 0]])\n",
        "    Rydot = np.array([[-np.sin(beta*t)*beta, 0, np.cos(beta*t)*beta], \n",
        "                      [0, 0, 0], \n",
        "                      [-np.cos(beta*t)*beta, 0, -np.sin(beta*t)*beta]])\n",
        "    Rzdot = np.array([[0, 0, 0], \n",
        "                      [0, -np.sin(gamma*t)*gamma, - np.cos(gamma*t)*gamma], \n",
        "                      [0, np.cos(gamma*t)*gamma, np.sin(gamma*t)*gamma]])\n",
        "    Rtx = Rx.T\n",
        "    Rty = Ry.T\n",
        "    Rtz = Rz.T \n",
        "    Rtxdot = Rxdot.T\n",
        "    Rtydot = Rydot.T\n",
        "    Rtzdot = Rzdot.T\n",
        "    Rdot = np.matmul(np.matmul(Rxdot, Ry), Rz) + np.matmul(np.matmul(Rx, Rydot), Rz) + np.matmul(np.matmul(Rx, Ry), Rzdot)\n",
        "    Rtdot = Rdot.T\n",
        "    R = np.matmul(np.matmul(Rx, Ry), Rz)\n",
        "    Rt = R.T\n",
        "    l = [[3.63452908e-02*t, 0, 0], [0, 1.14151210e-04*t, 0], [0, 0, 6.86282637e-05*t]]\n",
        "    ld = [[3.63452908e-02, 0, 0], [0, 1.14151210e-04, 0], [0, 0, 6.86282637e-05]]\n",
        "    s.append(np.matmul(np.matmul(Rdot, l), Rt) + np.matmul(np.matmul(R, ld), Rt) + np.matmul(np.matmul(R, l), Rtdot))\n",
        "  return s\n",
        "S = angular_velocity(0.1, 0.1, 0.1, vals)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvh9ktd-fjLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dA_dt(A, t):\n",
        "  alpha, beta, gamma = 0.1, 0.1, 0.1 \n",
        "  l = [[3.63452908e-02*t, 0, 0], [0, 1.14151210e-04*t, 0], [0, 0, 6.86282637e-05*t]]\n",
        "  ld = [[3.63452908e-02, 0, 0], [0, 1.14151210e-04, 0], [0, 0, 6.86282637e-05]]\n",
        "  Rx = np.array([[np.cos(alpha*t), -np.sin(alpha * t), 0],\n",
        "                 [np.sin(alpha*t), np.cos(alpha*t), 0],\n",
        "                 [0, 0, 1]])\n",
        "  Ry = np.array([[np.cos(beta*t), 0, np.sin(beta*t)], \n",
        "                 [0, 1, 0], \n",
        "                 [-np.sin(beta*t), 0, np.cos(beta*t)]])\n",
        "  Rz = np.array([[1, 0, 0], \n",
        "                 [0, np.cos(gamma*t), - np.sin(gamma*t)], \n",
        "                 [0, np.sin(gamma*t), np.cos(gamma*t)]]) \n",
        "\n",
        "  Rxdot = np.array([[-np.sin(alpha *t) *alpha, -np.cos(alpha*t) *alpha, 0],\n",
        "                    [np.cos(alpha*t)*alpha, -np.sin(alpha*t)*alpha, 0], \n",
        "                    [0, 0, 0]])\n",
        "  Rydot = np.array([[-np.sin(beta*t)*beta, 0, np.cos(beta*t)*beta],\n",
        "                    [0, 0, 0],\n",
        "                    [-np.cos(beta*t)*beta, 0, -np.sin(beta*t)*beta]])\n",
        "  Rzdot = np.array([[0, 0, 0],\n",
        "                    [0, -np.sin(gamma*t)*gamma, - np.cos(gamma*t)*gamma],\n",
        "                    [0, np.cos(gamma*t)*gamma, np.sin(gamma*t)*gamma]])\n",
        "  Rtx = Rx.T\n",
        "  Rty = Ry.T\n",
        "  Rtz = Rz.T \n",
        "  Rtxdot = Rxdot.T\n",
        "  Rtydot = Rydot.T\n",
        "  Rtzdot = Rzdot.T\n",
        "  Rdot = np.matmul(np.matmul(Rxdot, Ry), Rz) + np.matmul(np.matmul(Rx, Rydot), Rz) + np.matmul(np.matmul(Rx, Ry), Rzdot)\n",
        "  Rtdot = Rdot.T\n",
        "  R = np.matmul(np.matmul(Rx, Ry), Rz)\n",
        "  Rt = R.T\n",
        "  S = np.matmul(np.matmul(Rdot, l), Rt) + np.matmul(np.matmul(R, ld), Rt) + np.matmul(np.matmul(R, l), Rtdot)\n",
        "  return S.ravel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuJA3hpigh_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = np.linspace(0, 176,175 )\n",
        "Rx = np.array([[np.cos(0), -np.sin(0), 0], [np.sin(0), np.cos(0), 0], [0, 0, 1]])\n",
        "Ry = np.array([[np.cos(0), 0, np.sin(0)], [0, 1, 0], [-np.sin(0), 0, np.cos(0)]])\n",
        "Rz = np.array([[1, 0, 0], [0, np.cos(0), - np.sin(0)], [0, np.sin(0), np.cos(0)]])\n",
        "# A0 = np.matmul(np.matmul(Rx, Ry), Rz).ravel() \n",
        "A0 = np.zeros(9)\n",
        "As = odeint(dA_dt, A0, t)\n",
        "As = np.array(As)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adkZ7xoGlV3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "su = [a.reshape(3,3) for a in As]\n",
        "su = np.array(su)\n",
        "sulli = []\n",
        "for s in su:\n",
        "  sulli.append(np.matmul(b, s)[0])\n",
        "sulli = np.array(sulli) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL68iEAM82qL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%matplotlib notebook\n",
        "import matplotlib as mpl\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import gridspec\n",
        "colo = []\n",
        "mpl.rcParams['legend.fontsize'] = 10\n",
        "fig = plt.figure(figsize=(9, 6))\n",
        "G = gridspec.GridSpec(1, 2, width_ratios=[10, 1])\n",
        "ax1 = fig.add_subplot(G[0:2,0], projection='3d')\n",
        "for i in range(len(sulli-1)):\n",
        "  ax1.plot(sulli[i:i+2, 0], sulli[i:i+2, 1], sulli[i:i+2, 2], c = cm.jet(normalize(i)))\n",
        "ax2 = fig.add_subplot(G[0,1])\n",
        "cb1 = mpl.colorbar.ColorbarBase(ax2, cmap=cm.jet,\n",
        "                                 norm=norm,\n",
        "                                 orientation='vertical')\n",
        "cb1.set_label('time')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nTNpFYFsl51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "velocity = []\n",
        "for s in S:\n",
        "  velocity.append(np.matmul(b, s)[0])\n",
        "vel = np.array(velocity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxoKXDqAs5zf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%matplotlib notebook\n",
        "import matplotlib as mpl\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import gridspec\n",
        "colo = []\n",
        "mpl.rcParams['legend.fontsize'] = 10\n",
        "fig = plt.figure(figsize=(9, 6))\n",
        "G = gridspec.GridSpec(1, 2, width_ratios=[10, 1])\n",
        "ax1 = fig.add_subplot(G[0:2,0], projection='3d')\n",
        "for i in range(len(vel) - 1):\n",
        "  ax1.plot3D(vel[i:i+2,0], vel[i:i+2, 1], vel[i:i+2, 2], c=cm.Reds(normalize(i)))\n",
        "\n",
        "ax2 = fig.add_subplot(G[0,1])\n",
        "cb1 = mpl.colorbar.ColorbarBase(ax2, cmap=cm.Reds,\n",
        "                                 norm=norm,\n",
        "                                 orientation='vertical')\n",
        "cb1.set_label('time')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS_EiFvLx1fL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x, y, z = p[:, 0], p[:, 1], p[:, 2] \n",
        "x, y, z = sulli[:, 0], sulli[:, 1], sulli[:, 2] \n",
        "u, v, w = vel[:, 0], vel[:, 1], vel[:, 2]\n",
        "mpl.rcParams['legend.fontsize'] = 10\n",
        "#fig = plt.figure(figsize=(9, 6), dpi=1200)\n",
        "fig = plt.figure(figsize=(9, 6))\n",
        "G = gridspec.GridSpec(6, 2, width_ratios=[10, 1])\n",
        "ax1 = fig.add_subplot(G[:,0], projection='3d')\n",
        "for i in range(len(p) - 1):\n",
        "  ax1.plot3D(sulli[i:i+2,0], sulli[i:i+2, 1], sulli[i:i+2, 2], c=cm.Reds(normalize(i)))\n",
        "ax1.quiver(x[1::5], y[1::5], z[1::5], u[1::5], v[1::5], w[1::5],length=1, arrow_length_ratio=0.2, normalize=True)\n",
        "ax2 = fig.add_subplot(G[1:6,1])\n",
        "cb1 = mpl.colorbar.ColorbarBase(ax2, cmap=cm.Reds,\n",
        "                                norm=norm,\n",
        "                                orientation='vertical')\n",
        "cb1.set_label('time')\n",
        "plt.tight_layout()\n",
        "# plt.savefig(\"8-5-2020\", dpi = 1200)\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Syw7-eyE2Td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def dlamda_dA(lamda, A):\n",
        "#   print(A)\n",
        "#   print(lamda)\n",
        "#   lamda, v = np.linalg.eigh(np.array(A).reshape(3, 3)) \n",
        "#   dlamda_dA = np.matmul(v, v.T)\n",
        "#   return dlamda_dA.ravel()\n",
        "# lamda0 = [3.63452908e-02, 1.14151210e-04, 6.86282637e-05]\n",
        "# lams = odeint(dlamda_dA, lamda0, As)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwR1K0bQawAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def dA_dlamda(A, lamda, su):\n",
        "#   l, v = np.linalg.eig(A.reshape(3,3))\n",
        "#   a = np.linalg.inv(np.matmul(v.T, v))\n",
        "#   return a.ravel()\n",
        "# lamdas = np.linspace(0,50, 51)\n",
        "# a0 = np.diag([1, 1,1]).ravel()\n",
        "# AAs = odeint(dA_dlamda, a0, lamdas)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1EVOmuA1aa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# su = [a.reshape(3,3) for a in aas]\n",
        "# su = np.array(su)\n",
        "# sulli = []\n",
        "# for s in su:\n",
        "#   sulli.append(np.matmul(b, s)[0])\n",
        "# sulli = np.array(sulli) \n",
        "# import matplotlib as mpl\n",
        "# from mpl_toolkits.mplot3d import Axes3D\n",
        "# from matplotlib import gridspec\n",
        "# colo = []\n",
        "# mpl.rcParams['legend.fontsize'] = 10\n",
        "# fig = plt.figure(figsize=(9, 6))\n",
        "# G = gridspec.GridSpec(1, 2, width_ratios=[10, 1])\n",
        "# ax1 = fig.add_subplot(G[0:2,0], projection='3d')\n",
        "# for i in range(len(sulli-1)):\n",
        "#   ax1.plot(sulli[i:i+2, 0], sulli[i:i+2, 1], sulli[i:i+2, 2], c = cm.Reds(normalize(i)))\n",
        "\n",
        "# ax2 = fig.add_subplot(G[0,1])\n",
        "# cb1 = mpl.colorbar.ColorbarBase(ax2, cmap=cm.Reds,\n",
        "#                                  norm=norm,\n",
        "#                                  orientation='vertical')\n",
        "# cb1.set_label('time')\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ydSXE581lDq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}